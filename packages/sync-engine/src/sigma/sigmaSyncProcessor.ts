import type { PostgresClient } from '../database/postgres'
import type { Logger, ProcessNextResult, ResourceConfig } from '../types'
import { parseCsvObjects, runSigmaQueryAndDownloadCsv } from './sigmaApi'
import { SIGMA_INGESTION_CONFIGS } from './sigmaIngestionConfigs'
import {
  buildSigmaQuery,
  defaultSigmaRowToEntry,
  sigmaCursorFromEntry,
  type SigmaIngestionConfig,
} from './sigmaIngestion'

export type SigmaSyncProcessorConfig = {
  stripeSecretKey: string
  enableSigma?: boolean
  sigmaPageSizeOverride?: number
  sigmaSchemaName?: string
  logger?: Logger
}

/**
 * Handles all Sigma-specific sync logic:
 * - Building the sigma portion of the resource registry
 * - Fetching a single Sigma page (query + CSV parse + upsert)
 * - Resolving fallback cursors from destination tables
 * - Utility helpers (isSigmaResource, sigmaResultKey, getSupportedSigmaObjects)
 */
export class SigmaSyncProcessor {
  private readonly postgresClient: PostgresClient
  private readonly config: SigmaSyncProcessorConfig

  get sigmaSchemaName(): string {
    return this.config.sigmaSchemaName ?? 'sigma'
  }

  constructor(postgresClient: PostgresClient, config: SigmaSyncProcessorConfig) {
    this.postgresClient = postgresClient
    this.config = config
  }

  /**
   * Build the sigma portion of the resource registry.
   * Returns entries keyed by sigma table name with order starting after `maxCoreOrder`.
   */
  buildSigmaRegistryEntries(maxCoreOrder: number): Record<string, ResourceConfig> {
    const sigmaOverrideRaw = this.config.sigmaPageSizeOverride
    const sigmaOverride =
      typeof sigmaOverrideRaw === 'number' &&
      Number.isFinite(sigmaOverrideRaw) &&
      sigmaOverrideRaw > 0
        ? Math.floor(sigmaOverrideRaw)
        : undefined

    // TODO: Dedupe sigma tables that overlap with core Stripe objects (e.g. subscription_schedules).
    // Currently we just let core take precedence, but ideally sigma configs should exclude
    // tables that are already handled by the core Stripe API integration.
    return Object.fromEntries(
      Object.entries(SIGMA_INGESTION_CONFIGS).map(([key, sigmaConfig], idx) => {
        const pageSize = sigmaOverride
          ? Math.min(sigmaConfig.pageSize, sigmaOverride)
          : sigmaConfig.pageSize
        return [
          key,
          {
            order: maxCoreOrder + 1 + idx,
            supportsCreatedFilter: false,
            sigma: { ...sigmaConfig, pageSize },
          },
        ]
      })
    )
  }

  /**
   * Check whether a resource is backed by Sigma (has a `sigma` config in the registry).
   */
  isSigmaResource(resourceRegistry: Record<string, ResourceConfig>, object: string): boolean {
    return Boolean(resourceRegistry[object]?.sigma)
  }

  /**
   * Convert a snake_case sigma table name to camelCase for SyncBackfill result keys.
   */
  sigmaResultKey(tableName: string): string {
    return tableName.replace(/_([a-z0-9])/g, (_, ch: string) => ch.toUpperCase())
  }

  /**
   * Get the list of Sigma-backed object types that can be synced.
   * Only returns sigma objects when enableSigma is true.
   */
  getSupportedSigmaObjects(resourceRegistry: Record<string, ResourceConfig>): string[] {
    if (!this.config.enableSigma) {
      return []
    }

    return Object.entries(resourceRegistry)
      .filter(([, config]) => Boolean(config.sigma))
      .sort(([, a], [, b]) => a.order - b.order)
      .map(([key]) => key)
  }

  /**
   * Fetch the latest cursor from the destination table when no run cursor exists.
   * Queries the sigma schema for the max cursor column values.
   */
  async getSigmaFallbackCursorFromDestination(
    accountId: string,
    sigmaConfig: SigmaIngestionConfig
  ): Promise<string | null> {
    const sigmaSchema = this.sigmaSchemaName
    const cursorCols = sigmaConfig.cursor.columns
    const selectCols = cursorCols.map((c) => `"${c.column}"`).join(', ')
    const orderBy = cursorCols.map((c) => `"${c.column}" DESC`).join(', ')

    const result = await this.postgresClient.query(
      `SELECT ${selectCols}
       FROM "${sigmaSchema}"."${sigmaConfig.destinationTable}"
       WHERE "_account_id" = $1
       ORDER BY ${orderBy}
       LIMIT 1`,
      [accountId]
    )

    if (result.rows.length === 0) return null

    const row = result.rows[0] as Record<string, unknown>
    const entryForCursor: Record<string, unknown> = {}
    for (const c of cursorCols) {
      const v = row[c.column]
      if (v == null) {
        throw new Error(
          `Sigma fallback cursor query returned null for ${sigmaConfig.destinationTable}.${c.column}`
        )
      }
      if (c.type === 'timestamp') {
        const d = v instanceof Date ? v : new Date(String(v))
        if (Number.isNaN(d.getTime())) {
          throw new Error(
            `Sigma fallback cursor query returned invalid timestamp for ${sigmaConfig.destinationTable}.${c.column}: ${String(
              v
            )}`
          )
        }
        entryForCursor[c.column] = d.toISOString()
      } else {
        entryForCursor[c.column] = String(v)
      }
    }

    return sigmaCursorFromEntry(sigmaConfig, entryForCursor)
  }

  /**
   * Fetch one page of Sigma data, upsert to Postgres, and advance the cursor.
   */
  async fetchOneSigmaPage(
    accountId: string,
    resourceName: string,
    runStartedAt: Date,
    cursor: string | null,
    sigmaConfig: SigmaIngestionConfig
  ): Promise<ProcessNextResult> {
    if (!this.config.stripeSecretKey) {
      throw new Error('Sigma sync requested but stripeSecretKey is not configured.')
    }
    if (resourceName !== sigmaConfig.destinationTable) {
      throw new Error(
        `Sigma sync config mismatch: resourceName=${resourceName} destinationTable=${sigmaConfig.destinationTable}`
      )
    }

    const effectiveCursor =
      cursor ?? (await this.getSigmaFallbackCursorFromDestination(accountId, sigmaConfig))
    const sigmaSql = buildSigmaQuery(sigmaConfig, effectiveCursor)

    this.config.logger?.info(
      { object: resourceName, pageSize: sigmaConfig.pageSize, hasCursor: Boolean(effectiveCursor) },
      'Sigma sync: running query'
    )

    const { queryRunId, fileId, csv } = await runSigmaQueryAndDownloadCsv({
      apiKey: this.config.stripeSecretKey,
      sql: sigmaSql,
      logger: this.config.logger,
    })

    const rows = parseCsvObjects(csv)
    if (rows.length === 0) {
      await this.postgresClient.completeObjectSync(accountId, runStartedAt, resourceName)
      return { processed: 0, hasMore: false, runStartedAt }
    }

    const entries: Array<Record<string, unknown>> = rows.map((row) =>
      defaultSigmaRowToEntry(sigmaConfig, row)
    )

    this.config.logger?.info(
      { object: resourceName, rows: entries.length, queryRunId, fileId },
      'Sigma sync: upserting rows'
    )

    await this.postgresClient.upsertManyWithTimestampProtection(
      entries,
      resourceName,
      accountId,
      undefined,
      sigmaConfig.upsert,
      this.sigmaSchemaName
    )

    await this.postgresClient.incrementObjectProgress(
      accountId,
      runStartedAt,
      resourceName,
      entries.length
    )

    // Cursor: advance to the last row in the page (matches the ORDER BY in buildSigmaQuery()).
    const newCursor = sigmaCursorFromEntry(sigmaConfig, entries[entries.length - 1]!)
    await this.postgresClient.updateObjectCursor(accountId, runStartedAt, resourceName, newCursor)

    const hasMore = rows.length === sigmaConfig.pageSize
    if (!hasMore) {
      await this.postgresClient.completeObjectSync(accountId, runStartedAt, resourceName)
    }

    return { processed: entries.length, hasMore, runStartedAt }
  }
}
